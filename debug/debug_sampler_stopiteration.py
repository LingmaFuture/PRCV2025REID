#!/usr/bin/env python3
# debug_sampler_stopiteration.py
# è¯Šæ–­MultiModalBalancedSamplerçš„StopIterationé—®é¢˜

import torch
from datasets.dataset import MultiModalDataset, MultiModalBalancedSampler, infer_modalities_of_sample
from configs.config import TrainingConfig
from tools.split import split_ids, create_split_datasets
from collections import defaultdict

def diagnose_sampler_stopiteration():
    """è¯Šæ–­é‡‡æ ·å™¨StopIterationé—®é¢˜"""
    
    print("=== MultiModalBalancedSampler è¯Šæ–­ ===")
    
    # åŠ è½½é…ç½®å’Œæ•°æ®é›†
    config = TrainingConfig()
    full_dataset = MultiModalDataset(config, split='train')
    
    # è·å–æ‰€æœ‰äººå‘˜ID
    all_person_ids = [full_dataset.data_list[i]['person_id'] for i in range(len(full_dataset))]
    all_person_ids = sorted(list(set(all_person_ids)))
    
    # åˆ›å»ºperson_idåˆ°æ ‡ç­¾çš„æ˜ å°„
    pid2label = {pid: idx for idx, pid in enumerate(all_person_ids)}
    
    # æŒ‰IDåˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    train_ids, val_ids = split_ids(
        all_person_ids, 
        val_ratio=getattr(config, "val_ratio", 0.2),
        seed=getattr(config, "seed", 42)
    )
    
    # åˆ›å»ºè®­ç»ƒé›†
    train_dataset, _ = create_split_datasets(
        full_dataset, train_ids, val_ids, config
    )
    
    print(f"æ•°æ®é›†ä¿¡æ¯:")
    print(f"  è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"  è®­ç»ƒé›†IDæ•°: {len(train_ids)}")
    
    # åˆ†æè®­ç»ƒé›†ä¸­æ¯ä¸ªIDçš„æ¨¡æ€åˆ†å¸ƒ
    print(f"\n=== åˆ†æè®­ç»ƒé›†æ¨¡æ€åˆ†å¸ƒ ===")
    
    id_modality_stats = defaultdict(lambda: {'vis': 0, 'nir': 0, 'sk': 0, 'cp': 0, 'text': 0, 'total': 0})
    
    for idx in range(len(train_dataset)):
        sample = train_dataset.data_list[idx]
        pid = sample['person_id']
        modalities = infer_modalities_of_sample(train_dataset, idx)
        
        id_modality_stats[pid]['total'] += 1
        for mod in modalities:
            if mod in id_modality_stats[pid]:
                id_modality_stats[pid][mod] += 1
    
    # ç»Ÿè®¡å¯é…å¯¹çš„ID
    pairable_ids = []
    vis_only_ids = []
    non_vis_only_ids = []
    empty_ids = []
    
    for pid in train_ids:  # åªæ£€æŸ¥è®­ç»ƒé›†çš„ID
        if pid in id_modality_stats:
            stats = id_modality_stats[pid]
            has_vis = stats['vis'] > 0
            has_non_vis = any(stats[m] > 0 for m in ['nir', 'sk', 'cp', 'text'])
            
            if has_vis and has_non_vis:
                pairable_ids.append(pid)
            elif has_vis:
                vis_only_ids.append(pid)
            elif has_non_vis:
                non_vis_only_ids.append(pid)
            else:
                empty_ids.append(pid)
        else:
            empty_ids.append(pid)
    
    print(f"è®­ç»ƒé›†æ¨¡æ€ç»Ÿè®¡:")
    print(f"  å¯é…å¯¹IDæ•° (vis+évis): {len(pairable_ids)}")
    print(f"  ä»…vis IDæ•°: {len(vis_only_ids)}")
    print(f"  ä»…évis IDæ•°: {len(non_vis_only_ids)}")
    print(f"  æ— æ¨¡æ€IDæ•°: {len(empty_ids)}")
    print(f"  å¯é…å¯¹ç‡: {len(pairable_ids)/len(train_ids):.1%}")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªIDçš„è¯¦ç»†ä¿¡æ¯
    print(f"\n=== å‰10ä¸ªIDçš„æ¨¡æ€è¯¦æƒ… ===")
    for i, pid in enumerate(train_ids[:10]):
        if pid in id_modality_stats:
            stats = id_modality_stats[pid]
            has_vis = stats['vis'] > 0
            has_non_vis = any(stats[m] > 0 for m in ['nir', 'sk', 'cp', 'text'])
            status = "å¯é…å¯¹" if (has_vis and has_non_vis) else "ä¸å¯é…å¯¹"
            print(f"  ID {pid}: æ€»{stats['total']}, vis={stats['vis']}, "
                  f"nir={stats['nir']}, sk={stats['sk']}, cp={stats['cp']}, "
                  f"text={stats['text']} - {status}")
        else:
            print(f"  ID {pid}: æ— æ•°æ®")
    
    # ç°åœ¨æµ‹è¯•é‡‡æ ·å™¨
    print(f"\n=== æµ‹è¯•MultiModalBalancedSampler ===")
    
    batch_size = 32
    num_instances = 4
    
    if len(pairable_ids) == 0:
        print("âŒ æ²¡æœ‰å¯é…å¯¹çš„IDï¼Œé‡‡æ ·å™¨æ— æ³•å·¥ä½œï¼")
        print("\nğŸ”§ å»ºè®®ä¿®å¤æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥æ•°æ®é›†ä¸­çš„æ¨¡æ€æ ‡æ³¨æ˜¯å¦æ­£ç¡®")
        print("2. ä½¿ç”¨ModalAwarePKSamplerä½œä¸ºå¤‡é€‰")
        print("3. è°ƒæ•´modality inferenceé€»è¾‘")
        return False
    
    num_pids_per_batch = batch_size // num_instances
    if len(pairable_ids) < num_pids_per_batch:
        print(f"âŒ å¯é…å¯¹IDæ•°({len(pairable_ids)}) < æ¯æ‰¹éœ€è¦çš„IDæ•°({num_pids_per_batch})")
        print("é‡‡æ ·å™¨æ— æ³•ç”Ÿæˆå®Œæ•´çš„batch")
        print(f"\nğŸ”§ å»ºè®®ä¿®å¤æ–¹æ¡ˆ:")
        print(f"1. å‡å°‘batch_sizeåˆ° {len(pairable_ids) * num_instances}")
        print(f"2. å‡å°‘num_instances")
        print(f"3. ä½¿ç”¨æ›´å®½æ¾çš„é‡‡æ ·ç­–ç•¥")
        return False
    
    try:
        sampler = MultiModalBalancedSampler(
            train_dataset, 
            batch_size, 
            num_instances=num_instances
        )
        
        print(f"é‡‡æ ·å™¨åˆ›å»ºæˆåŠŸ:")
        print(f"  valid_pidsæ•°é‡: {len(sampler.valid_pids)}")
        print(f"  é¢„æœŸbatchæ•°é‡: {len(sampler)}")
        
        # å°è¯•ç”Ÿæˆç¬¬ä¸€ä¸ªbatch
        batch_iter = iter(sampler)
        first_batch = next(batch_iter)
        print(f"  é¦–æ‰¹ç”ŸæˆæˆåŠŸï¼Œå¤§å°: {len(first_batch)}")
        print("âœ… MultiModalBalancedSamplerå·¥ä½œæ­£å¸¸")
        return True
        
    except StopIteration:
        print("âŒ é‡‡æ ·å™¨ç«‹å³æŠ›å‡ºStopIteration")
        return False
    except Exception as e:
        print(f"âŒ é‡‡æ ·å™¨åˆ›å»º/ä½¿ç”¨å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = diagnose_sampler_stopiteration()
    if not success:
        print("\n" + "="*50)
        print("ğŸ”§ ç«‹å³ä¿®å¤å»ºè®®ï¼šåœ¨train.pyä¸­ä½¿ç”¨æ›´ç¨³å¥çš„é‡‡æ ·å™¨åˆ‡æ¢é€»è¾‘")