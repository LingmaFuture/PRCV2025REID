# tools/check_clip_projections.py
"""æ£€æŸ¥CLIPæ¨¡å‹çš„æŠ•å½±å±‚"""
import torch
from transformers import CLIPModel

def check_clip_projections():
    print("ğŸ” æ£€æŸ¥CLIPæŠ•å½±å±‚...")
    
    clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch16")
    
    print("\nğŸ“Š æ¨¡å‹é¡¶å±‚å±æ€§:")
    for attr in dir(clip_model):
        if not attr.startswith('_') and 'proj' in attr.lower():
            print(f"  - {attr}: {type(getattr(clip_model, attr))}")
    
    print("\nğŸ“Š æ£€æŸ¥å…·ä½“æŠ•å½±å±‚:")
    attrs_to_check = [
        'visual_projection', 'text_projection', 
        'vision_projection', 'text_proj',
        'vision_proj', 'visual_proj'
    ]
    
    for attr in attrs_to_check:
        if hasattr(clip_model, attr):
            proj = getattr(clip_model, attr)
            print(f"  âœ… {attr}: {type(proj)} - shape: {proj.weight.shape if hasattr(proj, 'weight') else 'N/A'}")
        else:
            print(f"  âŒ {attr}: ä¸å­˜åœ¨")
    
    # æ£€æŸ¥vision modelå’Œtext modelæ˜¯å¦æœ‰æŠ•å½±å±‚
    print("\nğŸ“Š Vision Model æŠ•å½±å±‚:")
    vision_model = clip_model.vision_model
    for attr in ['projection', 'proj', 'final_proj']:
        if hasattr(vision_model, attr):
            proj = getattr(vision_model, attr)
            print(f"  âœ… vision_model.{attr}: {type(proj)}")
    
    print("\nğŸ“Š Text Model æŠ•å½±å±‚:")
    text_model = clip_model.text_model
    for attr in ['projection', 'proj', 'final_proj']:
        if hasattr(text_model, attr):
            proj = getattr(text_model, attr)
            print(f"  âœ… text_model.{attr}: {type(proj)}")

if __name__ == "__main__":
    check_clip_projections()
