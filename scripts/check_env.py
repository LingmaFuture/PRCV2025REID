#!/usr/bin/env python3
"""
ç¯å¢ƒæ£€æŸ¥è„šæœ¬ - ç¡®ä¿è®­ç»ƒå‰ç¯å¢ƒå°±ç»ª
"""
import os
import sys
import importlib
import torch

def check_pytorch():
    """æ£€æŸ¥PyTorchç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥PyTorchç¯å¢ƒ...")
    print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            name = torch.cuda.get_device_name(i)
            mem = torch.cuda.get_device_properties(i).total_memory // 1024**3
            print(f"   GPU {i}: {name} ({mem}GB)")
    
def check_required_packages():
    """æ£€æŸ¥å¿…éœ€åŒ…"""
    required_packages = [
        'transformers',
        'datasets', 
        'numpy',
        'pandas',
        'tqdm',
        'sklearn',
        'PIL',
        'torchvision'
    ]
    
    print("\nğŸ“¦ æ£€æŸ¥å¿…éœ€åŒ…...")
    missing = []
    
    for pkg in required_packages:
        try:
            module = importlib.import_module(pkg)
            version = getattr(module, '__version__', 'unknown')
            print(f"   âœ… {pkg}: {version}")
        except ImportError:
            print(f"   âŒ {pkg}: æœªå®‰è£…")
            missing.append(pkg)
    
    if missing:
        print(f"\nâš ï¸ ç¼ºå°‘åŒ…: {', '.join(missing)}")
        print("å®‰è£…å‘½ä»¤: pip install " + ' '.join(missing))
        return False
    
    return True

def check_data_paths():
    """æ£€æŸ¥æ•°æ®è·¯å¾„"""
    print("\nğŸ“ æ£€æŸ¥æ•°æ®è·¯å¾„...")
    
    # æ£€æŸ¥é…ç½®ä¸­çš„è·¯å¾„
    try:
        from configs.config import TrainingConfig
        config = TrainingConfig()
        
        paths_to_check = [
            ("æ•°æ®æ ¹ç›®å½•", config.data_root),
            ("JSONæ ‡æ³¨æ–‡ä»¶", config.json_file),
            ("æ—¥å¿—ç›®å½•", config.log_dir),
            ("æ£€æŸ¥ç‚¹ç›®å½•", config.save_dir)
        ]
        
        all_good = True
        for name, path in paths_to_check:
            if os.path.exists(path):
                print(f"   âœ… {name}: {path}")
            else:
                print(f"   âŒ {name}: {path} (ä¸å­˜åœ¨)")
                all_good = False
                
        return all_good
        
    except Exception as e:
        print(f"   âŒ é…ç½®æ£€æŸ¥å¤±è´¥: {e}")
        return False

def check_memory():
    """æ£€æŸ¥å†…å­˜çŠ¶å†µ"""
    print("\nğŸ’¾ æ£€æŸ¥å†…å­˜çŠ¶å†µ...")
    
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            total = torch.cuda.get_device_properties(i).total_memory
            allocated = torch.cuda.memory_allocated(i)
            reserved = torch.cuda.memory_reserved(i)
            free = total - reserved
            
            print(f"   GPU {i} å†…å­˜:")
            print(f"     æ€»é‡: {total//1024**3:.1f}GB")
            print(f"     å·²åˆ†é…: {allocated//1024**3:.1f}GB") 
            print(f"     å·²ä¿ç•™: {reserved//1024**3:.1f}GB")
            print(f"     å¯ç”¨: {free//1024**3:.1f}GB")
            
            if free < 2 * 1024**3:  # å°äº2GB
                print(f"     âš ï¸ GPUå†…å­˜å¯èƒ½ä¸è¶³ï¼Œå»ºè®®æ¸…ç†æˆ–é™ä½batch_size")

def main():
    """ä¸»æ£€æŸ¥å‡½æ•°"""
    print("ğŸ”§ ç¯å¢ƒæ£€æŸ¥å¼€å§‹...\n")
    
    # å„é¡¹æ£€æŸ¥
    checks = [
        ("PyTorchç¯å¢ƒ", check_pytorch),
        ("å¿…éœ€åŒ…", check_required_packages), 
        ("æ•°æ®è·¯å¾„", check_data_paths),
        ("å†…å­˜çŠ¶å†µ", check_memory)
    ]
    
    all_passed = True
    
    for check_name, check_func in checks:
        try:
            result = check_func()
            if result is False:
                all_passed = False
        except Exception as e:
            print(f"   âŒ {check_name}æ£€æŸ¥å¼‚å¸¸: {e}")
            all_passed = False
    
    print("\n" + "="*50)
    if all_passed:
        print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡! å¯ä»¥å¼€å§‹è®­ç»ƒ")
        print("å¯åŠ¨å‘½ä»¤: python quick_start.py")
    else:
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤ä¸Šè¿°é—®é¢˜åå†è¯•")
    
    return all_passed

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)