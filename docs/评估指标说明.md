# ReID任务评估指标说明

## 概述

在行人重识别(ReID)任务中，我们使用两种不同的评估指标来监控模型性能：

1. **分类准确率 (Classification Accuracy)** - 用于训练过程监控
2. **检索性能指标 (Retrieval Metrics)** - 用于验证和最终评估

## 1. 分类准确率 (ClsAcc)

### 定义
分类准确率衡量模型在身份分类任务中的正确率：
```
准确率 = 正确分类的样本数 / 总样本数 × 100%
```

### 用途
- **训练监控**：在训练过程中实时显示，反映模型是否在学习
- **快速反馈**：计算简单快速，适合实时监控
- **直观理解**：容易理解，直接反映分类能力

### 计算方式
```python
# 在训练过程中
_, predicted = outputs['logits'].max(1)
correct += predicted.eq(labels).sum().item()
accuracy = 100. * correct / total
```

## 2. 检索性能指标

### mAP (Mean Average Precision)
- **定义**：平均精度均值，衡量检索的整体性能
- **计算**：对所有查询的平均精度求平均
- **范围**：0-1，越高越好
- **意义**：综合考虑了检索的准确性和完整性

### CMC (Cumulative Matching Characteristic)
- **CMC@1**：第一个匹配结果正确的比例
- **CMC@5**：前5个匹配结果中包含正确结果的比例
- **CMC@10**：前10个匹配结果中包含正确结果的比例

### 计算方式
```python
# 计算相似度矩阵
similarity = torch.mm(query_features, gallery_features.t())

# 对每个查询计算AP
for i in range(similarity.size(0)):
    sim_scores = similarity[i]
    query_label = query_labels[i]
    
    # 排序
    _, indices = torch.sort(sim_scores, descending=True)
    sorted_labels = gallery_labels[indices[:k]]
    
    # 计算AP
    matches = (sorted_labels == query_label).float()
    # ... 计算平均精度
```

## 为什么同时使用两种指标？

### 训练阶段 (分类准确率)
1. **实时监控**：训练过程中需要快速反馈
2. **计算效率**：分类准确率计算简单，不影响训练速度
3. **学习信号**：反映模型是否在正确学习身份分类

### 验证阶段 (检索指标)
1. **任务相关**：ReID本质是检索任务，mAP是标准指标
2. **全面评估**：mAP考虑了检索的准确性和完整性
3. **竞赛标准**：PRCV2025竞赛使用mAP@100作为主要评估指标

## 指标关系

### 正相关关系
- 分类准确率高的模型通常检索性能也较好
- 但两者不是完全线性关系

### 差异原因
1. **任务差异**：分类是判别任务，检索是排序任务
2. **评估方式**：分类看绝对正确性，检索看相对排序
3. **数据分布**：检索需要考虑跨模态匹配

## 实际应用建议

### 训练监控
- 主要关注分类准确率的变化趋势
- 准确率持续上升说明模型在学习

### 模型选择
- 以mAP@100为主要指标选择最佳模型
- 同时考虑CMC@1和CMC@5的平衡

### 最终评估
- 使用官方验证集生成提交文件
- 上传至竞赛平台获得最终mAP指标

## 注意事项

1. **验证集无标签**：官方验证集无法直接计算mAP
2. **本地验证**：只能在训练集划分的验证集上计算
3. **最终评估**：只有提交结果才能获得准确的官方指标
