# tools/test_fixes.py
"""
æµ‹è¯•ä¿®å¤æ•ˆæœçš„è„šæœ¬
éªŒè¯æ•°æ®é›†åˆ’åˆ†å’ŒSDMæŸå¤±ä¿®å¤
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import logging
from configs.config import TrainingConfig
from datasets.dataset import MultiModalDataset
from tools.split import split_ids, create_split_datasets, verify_split_integrity
from models.sdm_loss import sdm_loss_stable, SDMLoss

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def test_dataset_split():
    """æµ‹è¯•æ•°æ®é›†åˆ’åˆ†ä¿®å¤"""
    print("=" * 50)
    print("æµ‹è¯•æ•°æ®é›†åˆ’åˆ†ä¿®å¤")
    print("=" * 50)
    
    # åŠ è½½é…ç½®
    config = TrainingConfig()
    
    # åŠ è½½å®Œæ•´æ•°æ®é›†
    print("åŠ è½½å®Œæ•´æ•°æ®é›†...")
    full_dataset = MultiModalDataset(config, split='train')
    
    # è·å–æ‰€æœ‰äººå‘˜ID
    all_person_ids = [full_dataset.data_list[i]['person_id'] for i in range(len(full_dataset))]
    all_person_ids = sorted(list(set(all_person_ids)))
    print(f"æ€»äººå‘˜IDæ•°: {len(all_person_ids)}")
    print(f"æ€»æ ·æœ¬æ•°: {len(full_dataset.data_list)}")
    
    # æµ‹è¯•åˆ’åˆ†
    print("\næµ‹è¯•æ•°æ®é›†åˆ’åˆ†...")
    train_ids, val_ids = split_ids(all_person_ids, val_ratio=0.2, seed=42)
    
    print(f"è®­ç»ƒé›†IDæ•°: {len(train_ids)}")
    print(f"éªŒè¯é›†IDæ•°: {len(val_ids)}")
    print(f"éªŒè¯é›†æ¯”ä¾‹: {len(val_ids)/len(all_person_ids):.3f}")
    
    # éªŒè¯äº’æ–¥æ€§
    common_ids = train_ids & val_ids
    if len(common_ids) == 0:
        print("âœ… è®­ç»ƒé›†å’ŒéªŒè¯é›†IDäº’æ–¥")
    else:
        print(f"âŒ è®­ç»ƒé›†å’ŒéªŒè¯é›†å­˜åœ¨å…±åŒID: {common_ids}")
        return False
    
    # åˆ›å»ºåˆ’åˆ†åçš„æ•°æ®é›†
    print("\nåˆ›å»ºåˆ’åˆ†åçš„æ•°æ®é›†...")
    train_dataset, val_dataset = create_split_datasets(full_dataset, train_ids, val_ids, config)
    
    # éªŒè¯å®Œæ•´æ€§
    print("\néªŒè¯æ•°æ®é›†å®Œæ•´æ€§...")
    verify_split_integrity(train_dataset, val_dataset)
    
    # æ£€æŸ¥æ ·æœ¬æ•°
    expected_train_samples = sum(1 for item in full_dataset.data_list if item['person_id'] in train_ids)
    expected_val_samples = sum(1 for item in full_dataset.data_list if item['person_id'] in val_ids)
    
    print(f"\næ ·æœ¬æ•°éªŒè¯:")
    print(f"  è®­ç»ƒé›†: {len(train_dataset.data_list)} (æœŸæœ›: {expected_train_samples})")
    print(f"  éªŒè¯é›†: {len(val_dataset.data_list)} (æœŸæœ›: {expected_val_samples})")
    print(f"  æ€»è®¡: {len(train_dataset.data_list) + len(val_dataset.data_list)} (æœŸæœ›: {len(full_dataset.data_list)})")
    
    if (len(train_dataset.data_list) == expected_train_samples and 
        len(val_dataset.data_list) == expected_val_samples):
        print("âœ… æ•°æ®é›†åˆ’åˆ†æ ·æœ¬æ•°æ­£ç¡®")
        return True
    else:
        print("âŒ æ•°æ®é›†åˆ’åˆ†æ ·æœ¬æ•°ä¸æ­£ç¡®")
        return False


def test_sdm_loss():
    """æµ‹è¯•SDMæŸå¤±ä¿®å¤"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•SDMæŸå¤±ä¿®å¤")
    print("=" * 50)
    
    # æµ‹è¯•æ•°æ®
    batch_size = 16
    feature_dim = 512
    num_classes = 8
    
    print(f"æµ‹è¯•å‚æ•°: batch_size={batch_size}, feature_dim={feature_dim}, num_classes={num_classes}")
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    qry_features = torch.randn(batch_size, feature_dim)
    gal_features = torch.randn(batch_size, feature_dim)
    labels = torch.randint(0, num_classes, (batch_size,))
    
    # æ„é€ åŒèº«ä»½æŒ‡ç¤ºçŸ©é˜µ
    labels_qry = labels.view(-1, 1)
    labels_gal = labels.view(1, -1)
    y = (labels_qry == labels_gal).float()
    
    print(f"æ­£æ ·æœ¬æ•°é‡: {y.sum().item()}")
    
    # æµ‹è¯•å‡½æ•°ç‰ˆæœ¬
    print("\næµ‹è¯•å‡½æ•°ç‰ˆæœ¬SDMæŸå¤±...")
    loss_func = sdm_loss_stable(qry_features, gal_features, y, tau=0.1)
    print(f"å‡½æ•°ç‰ˆæœ¬æŸå¤±: {loss_func.item():.6f}")
    
    # æµ‹è¯•æ¨¡å—ç‰ˆæœ¬
    print("\næµ‹è¯•æ¨¡å—ç‰ˆæœ¬SDMæŸå¤±...")
    sdm_module = SDMLoss(temperature=0.1)
    loss_module, details = sdm_module(qry_features, gal_features, labels, return_details=True)
    print(f"æ¨¡å—ç‰ˆæœ¬æŸå¤±: {loss_module.item():.6f}")
    print(f"è¯¦ç»†ä¿¡æ¯: {details}")
    
    # éªŒè¯æŸå¤±ä¸ºæ­£
    if loss_func.item() >= 0 and loss_module.item() >= 0:
        print("âœ… SDMæŸå¤±è®¡ç®—æ­£ç¡®ï¼ˆéè´Ÿå€¼ï¼‰")
        return True
    else:
        print("âŒ SDMæŸå¤±è®¡ç®—é”™è¯¯ï¼ˆå‡ºç°è´Ÿå€¼ï¼‰")
        return False


def test_extreme_cases():
    """æµ‹è¯•æç«¯æƒ…å†µ"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æç«¯æƒ…å†µ")
    print("=" * 50)
    
    # æµ‹è¯•å…¨é›¶ç‰¹å¾
    print("æµ‹è¯•å…¨é›¶ç‰¹å¾...")
    batch_size = 8
    feature_dim = 512
    qry_features = torch.zeros(batch_size, feature_dim)
    gal_features = torch.zeros(batch_size, feature_dim)
    labels = torch.randint(0, 4, (batch_size,))
    
    labels_qry = labels.view(-1, 1)
    labels_gal = labels.view(1, -1)
    y = (labels_qry == labels_gal).float()
    
    try:
        loss = sdm_loss_stable(qry_features, gal_features, y, tau=0.1)
        print(f"å…¨é›¶ç‰¹å¾æŸå¤±: {loss.item():.6f}")
        print("âœ… å…¨é›¶ç‰¹å¾å¤„ç†æ­£å¸¸")
    except Exception as e:
        print(f"âŒ å…¨é›¶ç‰¹å¾å¤„ç†å¼‚å¸¸: {e}")
        return False
    
    # æµ‹è¯•å•æ ·æœ¬
    print("\næµ‹è¯•å•æ ·æœ¬...")
    qry_features = torch.randn(1, feature_dim)
    gal_features = torch.randn(1, feature_dim)
    labels = torch.tensor([0])
    
    labels_qry = labels.view(-1, 1)
    labels_gal = labels.view(1, -1)
    y = (labels_qry == labels_gal).float()
    
    try:
        loss = sdm_loss_stable(qry_features, gal_features, y, tau=0.1)
        print(f"å•æ ·æœ¬æŸå¤±: {loss.item():.6f}")
        print("âœ… å•æ ·æœ¬å¤„ç†æ­£å¸¸")
    except Exception as e:
        print(f"âŒ å•æ ·æœ¬å¤„ç†å¼‚å¸¸: {e}")
        return False
    
    return True


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•ä¿®å¤æ•ˆæœ...")
    
    # æµ‹è¯•æ•°æ®é›†åˆ’åˆ†
    split_ok = test_dataset_split()
    
    # æµ‹è¯•SDMæŸå¤±
    sdm_ok = test_sdm_loss()
    
    # æµ‹è¯•æç«¯æƒ…å†µ
    extreme_ok = test_extreme_cases()
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 50)
    print(f"æ•°æ®é›†åˆ’åˆ†: {'âœ… é€šè¿‡' if split_ok else 'âŒ å¤±è´¥'}")
    print(f"SDMæŸå¤±ä¿®å¤: {'âœ… é€šè¿‡' if sdm_ok else 'âŒ å¤±è´¥'}")
    print(f"æç«¯æƒ…å†µå¤„ç†: {'âœ… é€šè¿‡' if extreme_ok else 'âŒ å¤±è´¥'}")
    
    if split_ok and sdm_ok and extreme_ok:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä¿®å¤æˆåŠŸï¼")
        return True
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        return False


if __name__ == "__main__":
    main()
