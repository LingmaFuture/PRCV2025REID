#!/usr/bin/env python3
# test_stopiteration_fix.py
# å¿«é€ŸéªŒè¯StopIterationä¿®å¤æ•ˆæœ

import torch
import sys
from datasets.dataset import MultiModalDataset, ModalAwarePKSampler, compatible_collate_fn
from torch.utils.data import DataLoader
from configs.config import TrainingConfig
from tools.split import split_ids, create_split_datasets

def test_fix():
    """æµ‹è¯•ä¿®å¤åçš„é‡‡æ ·å™¨æ˜¯å¦å·¥ä½œ"""
    
    print("ğŸ§ª æµ‹è¯•StopIterationä¿®å¤æ•ˆæœ")
    print("=" * 40)
    
    try:
        # åŠ è½½é…ç½®å’Œæ•°æ®
        config = TrainingConfig()
        full_dataset = MultiModalDataset(config, split='train')
        
        # æ•°æ®é›†åˆ’åˆ†ï¼ˆæ¨¡æ‹Ÿtrain.pyçš„é€»è¾‘ï¼‰
        all_person_ids = [full_dataset.data_list[i]['person_id'] for i in range(len(full_dataset))]
        all_person_ids = sorted(list(set(all_person_ids)))
        train_ids, val_ids = split_ids(all_person_ids, val_ratio=0.2, seed=42)
        train_dataset, _ = create_split_datasets(full_dataset, train_ids, val_ids, config)
        
        print(f"æ•°æ®é›†ä¿¡æ¯:")
        print(f"  è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬, {len(train_ids)} ID")
        
        # æµ‹è¯•å‚æ•°
        actual_batch_size = 32
        num_instances = 4
        
        print(f"æ‰¹æ¬¡å‚æ•°: batch_size={actual_batch_size}, num_instances={num_instances}")
        
        # å‚æ•°æ ¡éªŒ
        assert actual_batch_size % num_instances == 0, \
            f"æ‰¹æ¬¡å¤§å°å¿…é¡»èƒ½è¢«å®ä¾‹æ•°æ•´é™¤: {actual_batch_size} % {num_instances} != 0"
        P = actual_batch_size // num_instances
        print(f"PÃ—Kç»“æ„: {P}Ã—{num_instances} = {actual_batch_size}")
        
        # åˆ›å»ºé‡‡æ ·å™¨ï¼ˆæŒ‰ä¿®å¤åçš„é€»è¾‘ï¼‰
        print(f"\nğŸ”§ åˆ›å»ºModalAwarePKSampler...")
        train_sampler = ModalAwarePKSampler(
            dataset=train_dataset,               
            batch_size=actual_batch_size,        
            num_instances=num_instances,         
            ensure_rgb=True,                     
            prefer_complete=True,                
            seed=42,
        )
        print(f"âœ… é‡‡æ ·å™¨åˆ›å»ºæˆåŠŸ")
        
        # åˆ›å»ºDataLoader
        print(f"\nğŸ”§ åˆ›å»ºDataLoader...")
        train_loader = DataLoader(
            train_dataset,
            batch_sampler=train_sampler,         
            num_workers=0,  # æµ‹è¯•æ—¶è®¾ä¸º0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            pin_memory=False,
            collate_fn=compatible_collate_fn     
        )
        print(f"âœ… DataLoaderåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ç”Ÿæˆbatch
        print(f"\nğŸ§ª æµ‹è¯•batchç”Ÿæˆ...")
        batch_count = 0
        pairable_stats = []
        
        for batch_idx, batch in enumerate(train_loader):
            if batch_idx >= 3:  # åªæµ‹è¯•å‰3ä¸ªbatch
                break
                
            labels = batch['person_id']
            modality_mask = batch.get('modality_mask', {})
            
            # ç»Ÿè®¡å¯é…å¯¹æ€§
            unique_ids = torch.unique(labels)
            pairable_count = 0
            
            for pid in unique_ids:
                pid_indices = (labels == pid)
                has_vis = modality_mask.get('vis', torch.zeros_like(labels))[pid_indices].any()
                has_non_vis = any(modality_mask.get(m, torch.zeros_like(labels))[pid_indices].any() 
                                 for m in ['nir', 'sk', 'cp', 'text'])
                if has_vis and has_non_vis:
                    pairable_count += 1
            
            pairable_ratio = pairable_count / len(unique_ids) if len(unique_ids) > 0 else 0
            pairable_stats.append(pairable_ratio)
            
            print(f"  Batch {batch_idx}: {len(labels)}æ ·æœ¬, {len(unique_ids)}ID, "
                  f"å¯é…å¯¹: {pairable_count}/{len(unique_ids)} ({pairable_ratio:.1%})")
            
            batch_count += 1
        
        avg_pairable_ratio = sum(pairable_stats) / len(pairable_stats) if pairable_stats else 0
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"  æˆåŠŸç”Ÿæˆbatchæ•°: {batch_count}")
        print(f"  å¹³å‡å¯é…å¯¹ç‡: {avg_pairable_ratio:.1%}")
        
        # åˆ¤æ–­ä¿®å¤æ•ˆæœ
        if batch_count > 0:
            print(f"âœ… StopIterationé—®é¢˜å·²ä¿®å¤ï¼")
            if avg_pairable_ratio >= 0.7:
                print(f"âœ… å¯é…å¯¹ç‡è‰¯å¥½ï¼ŒSDMæŸå¤±åº”è¯¥æ­£å¸¸å·¥ä½œ")
                return True
            else:
                print(f"âš ï¸ å¯é…å¯¹ç‡åä½ï¼Œå¯èƒ½ä»æœ‰éƒ¨åˆ†SDMæŸå¤±ä¸º0")
                return True
        else:
            print(f"âŒ ä»ç„¶æ— æ³•ç”Ÿæˆbatch")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_fix()
    if success:
        print(f"\nğŸš€ å¯ä»¥è¿è¡Œ python train.py å¼€å§‹è®­ç»ƒäº†!")
    else:
        print(f"\nğŸ” éœ€è¦è¿›ä¸€æ­¥è¯Šæ–­é—®é¢˜")
        sys.exit(1)