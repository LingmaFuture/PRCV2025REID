# tools/test_eval_protocol.py
"""
æµ‹è¯•å¤šæ¨¡æ€è¯„ä¼°åè®®
éªŒè¯å„ä¸ªç»„ä»¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import torch
import tempfile
import shutil
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from configs.config import TrainingConfig
from datasets.dataset import MultiModalDataset
from models.model import CLIPBasedMultiModalReIDModel
from tools.eval_mm_protocol import (
    build_index, build_gallery, build_queries, 
    FeatureExtractor, extract_gallery_feats,
    extract_query_feat, rank_and_metrics
)

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½å’Œç´¢å¼•æ„å»º"""
    print("=== æµ‹è¯•æ•°æ®åŠ è½½å’Œç´¢å¼•æ„å»º ===")
    
    try:
        # åˆ›å»ºé…ç½®
        config = TrainingConfig()
        
        # æ£€æŸ¥æ•°æ®è·¯å¾„
        if not os.path.exists(config.data_root):
            print(f"âš ï¸ æ•°æ®è·¯å¾„ä¸å­˜åœ¨: {config.data_root}")
            print("è¯·ç¡®ä¿æ•°æ®é›†å·²æ­£ç¡®æ”¾ç½®")
            return False
        
        if not os.path.exists(config.json_file):
            print(f"âš ï¸ æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {config.json_file}")
            print("è¯·ç¡®ä¿JSONæ ‡æ³¨æ–‡ä»¶å·²æ­£ç¡®æ”¾ç½®")
            return False
        
        # åŠ è½½æ•°æ®é›†ï¼ˆä½¿ç”¨è¾ƒå°‘çš„æ•°æ®è¿›è¡Œæµ‹è¯•ï¼‰
        dataset = MultiModalDataset(config, split='val')
        
        # æ„å»ºæ•°æ®ç´¢å¼•
        index = build_index(dataset)
        
        print(f"âœ… æ•°æ®ç´¢å¼•æ„å»ºæˆåŠŸï¼Œå…± {len(index)} ä¸ªèº«ä»½")
        
        # æ£€æŸ¥æ¨¡æ€è¦†ç›–
        modality_coverage = {}
        for pid, mods_map in index.items():
            for mod, items in mods_map.items():
                if items:
                    if mod not in modality_coverage:
                        modality_coverage[mod] = 0
                    modality_coverage[mod] += 1
        
        print("æ¨¡æ€è¦†ç›–æƒ…å†µ:")
        for mod, count in modality_coverage.items():
            print(f"  {mod}: {count} ä¸ªèº«ä»½")
        
        return index, dataset
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return False

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\n=== æµ‹è¯•æ¨¡å‹åŠ è½½ ===")
    
    try:
        # åˆ›å»ºé…ç½®
        config = TrainingConfig()
        
        # åˆ›å»ºæ¨¡å‹
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        model = CLIPBasedMultiModalReIDModel(config).to(device)
        model.set_num_classes(100)  # å‡è®¾100ä¸ªç±»åˆ«
        
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        model.eval()
        with torch.no_grad():
            # æµ‹è¯•å›¾åƒè¾“å…¥
            test_images = {
                'rgb': torch.randn(2, 3, 224, 224).to(device),
                'ir': torch.randn(2, 1, 224, 224).to(device)
            }
            test_texts = ["æµ‹è¯•æ–‡æœ¬1", "æµ‹è¯•æ–‡æœ¬2"]
            
            outputs = model(images=test_images, texts=test_texts)
            
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
            print(f"  ç‰¹å¾ç»´åº¦: {outputs['features'].shape}")
            print(f"  åˆ†ç±»è¾“å‡ºç»´åº¦: {outputs['logits'].shape}")
        
        return model, device
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def test_feature_extraction(model, device, index):
    """æµ‹è¯•ç‰¹å¾æå–"""
    print("\n=== æµ‹è¯•ç‰¹å¾æå– ===")
    
    try:
        # åˆ›å»ºç‰¹å¾æå–å™¨
        extractor = FeatureExtractor(model, device)
        
        # æ‰¾ä¸€ä¸ªæœ‰RGBå›¾åƒçš„æ ·æœ¬è¿›è¡Œæµ‹è¯•
        test_sample = None
        for pid, mods_map in index.items():
            if 'rgb' in mods_map and len(mods_map['rgb']) > 0:
                test_sample = mods_map['rgb'][0]
                break
        
        if test_sample is None:
            print("âš ï¸ æ‰¾ä¸åˆ°RGBæµ‹è¯•æ ·æœ¬")
            return False
        
        print(f"æµ‹è¯•æ ·æœ¬: {test_sample['img_path']}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(test_sample['img_path']):
            print(f"âš ï¸ æµ‹è¯•å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {test_sample['img_path']}")
            return False
        
        # æå–ç‰¹å¾
        feature = extractor.encode_rgb(test_sample['img_path'])
        
        print(f"âœ… RGBç‰¹å¾æå–æˆåŠŸï¼Œç»´åº¦: {feature.shape}")
        
        # æµ‹è¯•æ–‡æœ¬ç‰¹å¾æå–
        text_feature = extractor.encode_text("æµ‹è¯•æ–‡æœ¬")
        print(f"âœ… æ–‡æœ¬ç‰¹å¾æå–æˆåŠŸï¼Œç»´åº¦: {text_feature.shape}")
        
        return extractor
        
    except Exception as e:
        print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_query_building(index):
    """æµ‹è¯•æŸ¥è¯¢æ„å»º"""
    print("\n=== æµ‹è¯•æŸ¥è¯¢æ„å»º ===")
    
    try:
        import random
        rng = random.Random(42)
        
        # æµ‹è¯•å„ç§æ¨¡æ€ç»„åˆ
        for k in [1, 2, 3, 4]:
            queries = build_queries(index, mode_k=k, rng=rng)
            print(f"MM-{k}: {len(queries)} ä¸ªæŸ¥è¯¢")
            
            if queries:
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæŸ¥è¯¢çš„è¯¦æƒ…
                first_query = queries[0]
                print(f"  ç¤ºä¾‹æŸ¥è¯¢: PID={first_query['pid']}, "
                      f"æ¨¡æ€={first_query['modalities']}")
        
        print("âœ… æŸ¥è¯¢æ„å»ºæˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢æ„å»ºå¤±è´¥: {e}")
        return False

def test_gallery_building(index):
    """æµ‹è¯•Galleryæ„å»º"""
    print("\n=== æµ‹è¯•Galleryæ„å»º ===")
    
    try:
        gallery = build_gallery(index)
        print(f"âœ… Galleryæ„å»ºæˆåŠŸï¼Œå…± {len(gallery)} å¼ RGBå›¾åƒ")
        
        if gallery:
            print(f"  ç¤ºä¾‹Galleryé¡¹: {gallery[0]}")
        
        return gallery
        
    except Exception as e:
        print(f"âŒ Galleryæ„å»ºå¤±è´¥: {e}")
        return False

def test_small_evaluation(index, extractor, gallery):
    """æµ‹è¯•å°è§„æ¨¡è¯„ä¼°"""
    print("\n=== æµ‹è¯•å°è§„æ¨¡è¯„ä¼° ===")
    
    try:
        # åˆ›å»ºä¸´æ—¶ç¼“å­˜ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # åªå–å‰5ä¸ªGalleryæ ·æœ¬è¿›è¡Œæµ‹è¯•
            small_gallery = gallery[:5] if len(gallery) > 5 else gallery
            
            if not small_gallery:
                print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„Galleryæ ·æœ¬")
                return False
            
            print(f"æµ‹è¯•Galleryå¤§å°: {len(small_gallery)}")
            
            # æå–Galleryç‰¹å¾ï¼ˆå°è§„æ¨¡ï¼‰
            print("æå–Galleryç‰¹å¾...")
            
            feats, meta = [], []
            for item in small_gallery:
                try:
                    if os.path.exists(item["img_path"]):
                        f = extractor.encode_rgb(item["img_path"])
                        f = torch.nn.functional.normalize(f.float().view(1, -1)).squeeze(0)
                        feats.append(f.cpu())
                        meta.append({
                            "img_id": item.get("img_id", None),
                            "pid": int(item["pid"]),
                            "camid": item.get("camid", None)
                        })
                    else:
                        print(f"âš ï¸ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {item['img_path']}")
                except Exception as e:
                    print(f"âš ï¸ æå–ç‰¹å¾å¤±è´¥ {item['img_path']}: {e}")
            
            if not feats:
                print("âš ï¸ æ²¡æœ‰æˆåŠŸæå–çš„Galleryç‰¹å¾")
                return False
            
            gallery_feats = torch.stack(feats, 0)
            print(f"âœ… Galleryç‰¹å¾æå–æˆåŠŸï¼Œå½¢çŠ¶: {gallery_feats.shape}")
            
            # æ„å»ºæŸ¥è¯¢ï¼ˆåªæµ‹è¯•MM-1ï¼‰
            import random
            rng = random.Random(42)
            queries = build_queries(index, mode_k=1, rng=rng)
            
            # åªå–å‰2ä¸ªæŸ¥è¯¢è¿›è¡Œæµ‹è¯•
            test_queries = queries[:2] if len(queries) > 2 else queries
            
            if not test_queries:
                print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æŸ¥è¯¢æ ·æœ¬")
                return False
            
            print(f"æµ‹è¯•æŸ¥è¯¢æ•°é‡: {len(test_queries)}")
            
            # ç®€å•çš„è¯„ä¼°æµ‹è¯•
            weight_cfg = {"ir": 1.0, "cpencil": 1.0, "sketch": 1.0, "text": 1.2}
            
            for i, q in enumerate(test_queries):
                try:
                    print(f"æµ‹è¯•æŸ¥è¯¢ {i+1}: PID={q['pid']}, æ¨¡æ€={q['modalities']}")
                    
                    # æå–æŸ¥è¯¢ç‰¹å¾
                    q_feat = extract_query_feat(q, extractor, weight_cfg)
                    print(f"  æŸ¥è¯¢ç‰¹å¾ç»´åº¦: {q_feat.shape}")
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦
                    q_feat_norm = torch.nn.functional.normalize(q_feat.view(1, -1), dim=-1)
                    gallery_feats_norm = torch.nn.functional.normalize(gallery_feats, dim=-1)
                    sims = q_feat_norm @ gallery_feats_norm.T
                    
                    print(f"  ç›¸ä¼¼åº¦èŒƒå›´: {sims.min().item():.3f} ~ {sims.max().item():.3f}")
                    
                except Exception as e:
                    print(f"  âŒ æŸ¥è¯¢ {i+1} å¤±è´¥: {e}")
            
            print("âœ… å°è§„æ¨¡è¯„ä¼°æµ‹è¯•å®Œæˆ")
            return True
            
    except Exception as e:
        print(f"âŒ å°è§„æ¨¡è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å¤šæ¨¡æ€è¯„ä¼°åè®®")
    print("=" * 50)
    
    # 1. æµ‹è¯•æ•°æ®åŠ è½½
    data_result = test_data_loading()
    if not data_result:
        print("âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„å’Œæ ¼å¼")
        return
    
    index, dataset = data_result
    
    # 2. æµ‹è¯•æ¨¡å‹åŠ è½½
    model_result = test_model_loading()
    if not model_result:
        print("âŒ æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥")
        return
    
    model, device = model_result
    
    # 3. æµ‹è¯•ç‰¹å¾æå–
    extractor = test_feature_extraction(model, device, index)
    if not extractor:
        print("âŒ ç‰¹å¾æå–æµ‹è¯•å¤±è´¥")
        return
    
    # 4. æµ‹è¯•æŸ¥è¯¢æ„å»º
    if not test_query_building(index):
        print("âŒ æŸ¥è¯¢æ„å»ºæµ‹è¯•å¤±è´¥")
        return
    
    # 5. æµ‹è¯•Galleryæ„å»º
    gallery = test_gallery_building(index)
    if not gallery:
        print("âŒ Galleryæ„å»ºæµ‹è¯•å¤±è´¥")
        return
    
    # 6. æµ‹è¯•å°è§„æ¨¡è¯„ä¼°
    if not test_small_evaluation(index, extractor, gallery):
        print("âŒ å°è§„æ¨¡è¯„ä¼°æµ‹è¯•å¤±è´¥")
        return
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éƒ½é€šè¿‡ï¼è¯„ä¼°åè®®å¯ä»¥æ­£å¸¸ä½¿ç”¨")
    print("=" * 50)
    
    print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
    print("1. ç¡®ä¿å·²è®­ç»ƒå¥½æ¨¡å‹å¹¶ä¿å­˜æƒé‡")
    print("2. è¿è¡Œå®Œæ•´è¯„ä¼°:")
    print("   python tools/eval_mm_protocol.py --dataset_root ./data/train --model_path ./checkpoints/best_model.pth")
    print("3. å¦‚éœ€è¦ï¼Œå¯ä»¥ä¿®æ”¹æƒé‡é…ç½®å’Œå…¶ä»–å‚æ•°")

if __name__ == "__main__":
    main()
